{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f904db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e520ee",
   "metadata": {},
   "source": [
    "## Question 1: Top 10 Bundesliga teams over entire period\n",
    "\n",
    "**Metric: Points Per Game (PPG)**\n",
    "- 3 points for win\n",
    "- 1 point for draw\n",
    "- 0 points for loss\n",
    "\n",
    "Same point system as used in real life, ensures fairness, eliminates goal outliers and also gives points for draws. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6e2f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/bundesliga.csv')\n",
    "\n",
    "# Convert Date to datetime \n",
    "df['Date'] = pd.to_datetime(df['Date'], format='mixed', dayfirst=True)\n",
    "\n",
    "# Quick look\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDate range: {df['Date'].min()} to {df['Date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc6d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5318d90",
   "metadata": {},
   "source": [
    "## Calculate Points for Each Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0bce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_team_stats(df):\n",
    "    stats = {}\n",
    "    \n",
    "    # Process matches\n",
    "    for _, row in df.iterrows():\n",
    "        home_team = row['HomeTeam']\n",
    "        away_team = row['AwayTeam']\n",
    "        result = row['FTR']\n",
    "        \n",
    "        # Initialize teams if not seen before\n",
    "        if home_team not in stats:\n",
    "            stats[home_team] = {'games': 0, 'points': 0}\n",
    "        if away_team not in stats:\n",
    "            stats[away_team] = {'games': 0, 'points': 0}\n",
    "        \n",
    "        # Update home team stats\n",
    "        stats[home_team]['games'] += 1\n",
    "        \n",
    "        if result == 'H': \n",
    "            stats[home_team]['points'] += 3\n",
    "        elif result == 'D':     \n",
    "            stats[home_team]['points'] += 1\n",
    "        \n",
    "        # Update away team stats\n",
    "        stats[away_team]['games'] += 1\n",
    "        \n",
    "        if result == 'A': \n",
    "            stats[away_team]['points'] += 3\n",
    "        elif result == 'D':     \n",
    "            stats[away_team]['points'] += 1\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267529c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate stats\n",
    "team_stats = calculate_team_stats(df)\n",
    "\n",
    "# Convert to df\n",
    "stats_df = pd.DataFrame.from_dict(team_stats, orient='index')\n",
    "stats_df.index.name = 'Team'\n",
    "stats_df.reset_index(inplace=True)\n",
    "\n",
    "# Calculate derived metrics\n",
    "stats_df['PPG'] = stats_df['points'] / stats_df['games']\n",
    "\n",
    "print(f\"Total teams in dataset: {len(stats_df)}\")\n",
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb61dca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter teams with min 100 games and get top 10\n",
    "min_games = 100\n",
    "\n",
    "filtered_stats = stats_df[stats_df['games'] >= min_games]\n",
    "top_10 = filtered_stats.sort_values('PPG', ascending=False).head(10)\n",
    "\n",
    "print(f\"=== TOP 10 BUNDESLIGA TEAMS (1993-2018) ===\")\n",
    "print(f\"Filtered by minimum {min_games} games | Teams remaining: {len(filtered_stats)}\\n\")\n",
    "\n",
    "top_10[['Team', 'games', 'PPG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ae1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of top 10 teams\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# PPG comparison\n",
    "ax.barh(range(len(top_10)), top_10['PPG'].values, color='steelblue')\n",
    "ax.set_yticks(range(len(top_10)))\n",
    "ax.set_yticklabels(top_10['Team'].values)\n",
    "ax.set_xlabel('Points Per Game', fontsize=12)\n",
    "ax.set_title('Top 10 Bundesliga Teams by PPG (1993-2018)', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(top_10['PPG'].values):\n",
    "    ax.text(v + 0.02, i, f'{v:.3f}', va='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994c1d5a",
   "metadata": {},
   "source": [
    "## Question 2: Total goals prediction\n",
    "\n",
    "A model is implemented to predict total goals in football matches. Since bets are placed at halftime the target variable for prediction is the total goals in the second half of the matches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825ba950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing halftime data (1993/94 and 1994/95 seasons)\n",
    "df_clean = df.dropna(subset=['HTHG', 'HTAG', 'HTR']).copy()\n",
    "\n",
    "print(f\"\\nAfter dropping missing halftime data: {df_clean.shape}\")\n",
    "print(f\"Rows dropped: {len(df) - len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d2919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable: Total goals in second half\n",
    "df_clean['second_half_goals'] = (df_clean['FTHG'] - df_clean['HTHG']) + (df_clean['FTAG'] - df_clean['HTAG'])\n",
    "\n",
    "# Halftime features\n",
    "df_clean['ht_total_goals'] = df_clean['HTHG'] + df_clean['HTAG']\n",
    "df_clean['ht_goal_diff'] = df_clean['HTHG'] - df_clean['HTAG']\n",
    "\n",
    "df_clean['year'] = df_clean['Date'].dt.year\n",
    "\n",
    "# Calculate running average of second half goals for each team.\n",
    "def calculate_historical_avg(df, team_col):\n",
    "    is_home = team_col == 'HomeTeam'\n",
    "    team_avgs = {}\n",
    "    result = []\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        team = row[team_col]\n",
    "        \n",
    "        # Get average from prior matches only\n",
    "        if team in team_avgs and team_avgs[team]['games'] > 0:\n",
    "            avg = team_avgs[team]['sh_cumulative_goals'] / team_avgs[team]['games']\n",
    "        else:\n",
    "            avg = np.nan\n",
    "        \n",
    "        result.append(avg)\n",
    "        \n",
    "        # Update running totals after recording the average\n",
    "        if team not in team_avgs:\n",
    "            team_avgs[team] = {'sh_cumulative_goals': 0, 'games': 0}\n",
    "        \n",
    "        sh_goals = row['FTHG'] - row['HTHG'] if is_home else row['FTAG'] - row['HTAG']\n",
    "        team_avgs[team]['sh_cumulative_goals'] += sh_goals\n",
    "        team_avgs[team]['games'] += 1\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Calculate historical averages\n",
    "df_clean['home_team_hist_sh_goals'] = calculate_historical_avg(df_clean, 'HomeTeam')\n",
    "df_clean['away_team_hist_sh_goals'] = calculate_historical_avg(df_clean, 'AwayTeam')\n",
    "\n",
    "# Fill NaNs: avg. about 0.8 goals per team per second half\n",
    "AVG_SH_GOALS_PER_TEAM = 0.8\n",
    "\n",
    "df_clean['home_team_hist_sh_goals'] = df_clean['home_team_hist_sh_goals'].fillna(AVG_SH_GOALS_PER_TEAM)\n",
    "df_clean['away_team_hist_sh_goals'] = df_clean['away_team_hist_sh_goals'].fillna(AVG_SH_GOALS_PER_TEAM)\n",
    "\n",
    "df_clean['combined_hist_sh_goals'] = df_clean['home_team_hist_sh_goals'] + df_clean['away_team_hist_sh_goals']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf5575e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split: Train on data before 2016, test on 2016-2018\n",
    "train_cutoff_year = 2016\n",
    "train_df = df_clean[df_clean['year'] < train_cutoff_year].copy()\n",
    "test_df = df_clean[df_clean['year'] >= train_cutoff_year].copy()\n",
    "\n",
    "print(f\"\\n=== Train-Test Split ===\")\n",
    "print(f\"Train set: {len(train_df)} matches ({train_df['year'].min()}-{train_df['year'].max()})\")\n",
    "print(f\"Test set: {len(test_df)} matches ({test_df['year'].min()}-{test_df['year'].max()})\")\n",
    "\n",
    "# Features\n",
    "feature_cols = [\n",
    "    'ht_total_goals', 'ht_goal_diff',  # Half time features\n",
    "    'home_team_hist_sh_goals',         # Historical: home team's avg 2nd half goals\n",
    "    'away_team_hist_sh_goals',         # Historical: away team's avg 2nd half goals\n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['second_half_goals']\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['second_half_goals']\n",
    "\n",
    "print(f\"\\nFeatures used: {len(feature_cols)}\")\n",
    "for f in feature_cols:\n",
    "    print(f\"  - {f}\")\n",
    "X_train.describe()\n",
    "X_test.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ace620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline model: Predict mean of training \n",
    "baseline_pred = np.full(len(y_test), y_train.mean())\n",
    "baseline_mae = mean_absolute_error(y_test, baseline_pred)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_test, baseline_pred))\n",
    "\n",
    "print(f\"\\n=== Baseline (Predict Mean) ===\")\n",
    "print(f\"Mean second half goals (train): {y_train.mean():.3f}\")\n",
    "print(f\"MAE: {baseline_mae:.3f}\")\n",
    "print(f\"RMSE: {baseline_rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c7021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Regressor\n",
    "print(f\"\\nTraining Random Forest\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=10,\n",
    "    min_samples_split=20,\n",
    "    min_samples_leaf=10,\n",
    "    random_state=42,\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_pred_train = rf_model.predict(X_train)\n",
    "rf_pred_test = rf_model.predict(X_test)\n",
    "\n",
    "rf_mae_train = mean_absolute_error(y_train, rf_pred_train)\n",
    "rf_rmse_train = np.sqrt(mean_squared_error(y_train, rf_pred_train))\n",
    "rf_r2_train = r2_score(y_train, rf_pred_train)\n",
    "\n",
    "rf_mae_test = mean_absolute_error(y_test, rf_pred_test)\n",
    "rf_rmse_test = np.sqrt(mean_squared_error(y_test, rf_pred_test))\n",
    "rf_r2_test = r2_score(y_test, rf_pred_test)\n",
    "\n",
    "print(f\"\\nTrain Performance:\")\n",
    "print(f\"  MAE: {rf_mae_train:.3f}\")\n",
    "print(f\"  RMSE: {rf_rmse_train:.3f}\")\n",
    "print(f\"  R²: {rf_r2_train:.3f}\")\n",
    "\n",
    "print(f\"\\nTest Performance:\")\n",
    "print(f\"  MAE: {rf_mae_test:.3f}\")\n",
    "print(f\"  RMSE: {rf_rmse_test:.3f}\")\n",
    "print(f\"  R²: {rf_r2_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92e1cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Plot: Test Set\n",
    "residuals = y_test - rf_pred_test\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "scatter = ax.scatter(rf_pred_test, residuals, c=y_test, cmap='viridis', alpha=0.6)\n",
    "ax.axhline(0, color='red', linestyle='--')\n",
    "ax.set_xlabel('Predicted Second Half Goals')\n",
    "ax.set_ylabel('Residuals (Actual - Predicted)')\n",
    "ax.set_title('Residual Plot (colored by actual goals)')\n",
    "plt.colorbar(scatter, ax=ax, label='Actual Goals')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff38e8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance plot\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance (Random Forest) ===\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(range(len(feature_importance)), feature_importance['importance'].values)\n",
    "plt.yticks(range(len(feature_importance)), feature_importance['feature'].values)\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
